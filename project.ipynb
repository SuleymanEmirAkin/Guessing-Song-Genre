{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project \n",
    "\n",
    "This document is a modified version of project file used in Data 8 course of University of Berkeley.\n",
    "\n",
    "Coder: Suleyman Emir Akin\n",
    "\n",
    "You will build a classifier that guesses whether a song is hip-hop or country, using only the number of times words appear in the song's lyrics.  By the end of the project, you should know how to:\n",
    "\n",
    "1. Build a k-nearest-neighbors classifier.\n",
    "2. Test a classifier on data.\n",
    "3. Evaluate different sets of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, but please don't change it.\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The Dataset\n",
    "\n",
    "Our dataset is a table of songs, each with a name, an artist, and a genre.  For each song, we also know how frequently certain words occur in that song.  More precisely, we have a list of approximately 5000 words.  For each of these words, for each song, each item in the table describes the proportion of the song's lyrics that are the particular word.\n",
    "\n",
    "For example, the lyrics of \"In Your Eyes\" is 168 words long. The word \"like\" appears twice:  $\\frac{2}{168} \\approx 0.0119$ of the words in the song. Similarly, the word \"love\" appears 10 times: $\\frac{10}{168} \\approx 0.0595$ of the words. Therefore, `lyrics.where(\"Title\", \"In Your Eyes\").column(\"like\").item(0)` is about $0.0119$, and `lyrics.where(\"Title\", \"In Your Eyes\").column(\"love\").item(0)` is about $0.0595$.\n",
    "\n",
    "Our dataset doesn't contain all information about a song.  For example, it doesn't include the total number of words in each song, or information about the order of words in the song, let alone the melody, instruments, or rhythm. Nonetheless, you may find that word counts alone are sufficient to build an accurate genre classifier.\n",
    "\n",
    "Run the cell below to read the `lyrics` table. **It may take up to a minute to load.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Genre</th>\n",
       "      <th>i</th>\n",
       "      <th>the</th>\n",
       "      <th>you</th>\n",
       "      <th>to</th>\n",
       "      <th>and</th>\n",
       "      <th>a</th>\n",
       "      <th>me</th>\n",
       "      <th>...</th>\n",
       "      <th>writer</th>\n",
       "      <th>motivo</th>\n",
       "      <th>bake</th>\n",
       "      <th>insist</th>\n",
       "      <th>wel</th>\n",
       "      <th>santo</th>\n",
       "      <th>pe</th>\n",
       "      <th>gee</th>\n",
       "      <th>colleg</th>\n",
       "      <th>kad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slicker Than Your Average</td>\n",
       "      <td>Craig David</td>\n",
       "      <td>Hip-hop</td>\n",
       "      <td>0.049536</td>\n",
       "      <td>0.017028</td>\n",
       "      <td>0.035604</td>\n",
       "      <td>0.020124</td>\n",
       "      <td>0.007740</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Right There</td>\n",
       "      <td>MF Grimm</td>\n",
       "      <td>Hip-hop</td>\n",
       "      <td>0.037825</td>\n",
       "      <td>0.054374</td>\n",
       "      <td>0.023641</td>\n",
       "      <td>0.049645</td>\n",
       "      <td>0.009456</td>\n",
       "      <td>0.016548</td>\n",
       "      <td>0.018913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Talkin' All That</td>\n",
       "      <td>Cashis</td>\n",
       "      <td>Hip-hop</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>0.049645</td>\n",
       "      <td>0.051418</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>0.033688</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It Only Hurts Me When I Cry</td>\n",
       "      <td>Raul Malo</td>\n",
       "      <td>Country</td>\n",
       "      <td>0.096491</td>\n",
       "      <td>0.074561</td>\n",
       "      <td>0.030702</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.021930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is It Too Late Now</td>\n",
       "      <td>Lester Flatt &amp; Earl Scruggs</td>\n",
       "      <td>Country</td>\n",
       "      <td>0.043902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.034146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4979 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Title                       Artist    Genre  \\\n",
       "0    Slicker Than Your Average                  Craig David  Hip-hop   \n",
       "1                  Right There                     MF Grimm  Hip-hop   \n",
       "2             Talkin' All That                       Cashis  Hip-hop   \n",
       "3  It Only Hurts Me When I Cry                    Raul Malo  Country   \n",
       "4           Is It Too Late Now  Lester Flatt & Earl Scruggs  Country   \n",
       "\n",
       "          i       the       you        to       and         a        me  ...  \\\n",
       "0  0.049536  0.017028  0.035604  0.020124  0.007740  0.006192  0.058824  ...   \n",
       "1  0.037825  0.054374  0.023641  0.049645  0.009456  0.016548  0.018913  ...   \n",
       "2  0.056738  0.049645  0.051418  0.010638  0.026596  0.033688  0.007092  ...   \n",
       "3  0.096491  0.074561  0.030702  0.017544  0.026316  0.017544  0.021930  ...   \n",
       "4  0.043902  0.000000  0.073171  0.019512  0.000000  0.014634  0.034146  ...   \n",
       "\n",
       "   writer  motivo  bake  insist  wel  santo   pe  gee  colleg  kad  \n",
       "0     0.0     0.0   0.0     0.0    0    0.0  0.0  0.0     0.0    0  \n",
       "1     0.0     0.0   0.0     0.0    0    0.0  0.0  0.0     0.0    0  \n",
       "2     0.0     0.0   0.0     0.0    0    0.0  0.0  0.0     0.0    0  \n",
       "3     0.0     0.0   0.0     0.0    0    0.0  0.0  0.0     0.0    0  \n",
       "4     0.0     0.0   0.0     0.0    0    0.0  0.0  0.0     0.0    0  \n",
       "\n",
       "[5 rows x 4979 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just run this cell.\n",
    "lyrics = pd.read_csv('lyrics_clean.csv')\n",
    "\n",
    "# The first 5 rows of the table\n",
    "lyrics.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All titles are unique. The `row_for_title` function provides fast access to the one row for each title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title     It Only Hurts Me When I Cry\n",
       "Artist                      Raul Malo\n",
       "Genre                         Country\n",
       "i                            0.096491\n",
       "the                          0.074561\n",
       "                     ...             \n",
       "santo                             0.0\n",
       "pe                                0.0\n",
       "gee                               0.0\n",
       "colleg                            0.0\n",
       "kad                                 0\n",
       "Name: 3, Length: 4979, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#title_index = lyrics.index_by('Title')\n",
    "def row_for_title(title):\n",
    "    return lyrics[ lyrics[\"Title\"] == title ].iloc[0] \n",
    "# to see an example\n",
    "row_for_title(\"It Only Hurts Me When I Cry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset was extracted from the Million Song Dataset (http://labrosa.ee.columbia.edu/millionsong/). Specifically, we are using the complementary datasets from musiXmatch (http://labrosa.ee.columbia.edu/millionsong/musixmatch) and Last.fm (http://labrosa.ee.columbia.edu/millionsong/lastfm).\n",
    "\n",
    "The counts of common words in the lyrics for all of these songs are provided by the musiXmatch dataset (called a bag-of-words format). Only the top 5000 most common words are represented. For each song, we divided the number of occurrences of each word by the total number of word occurrences in the lyrics of that song.\n",
    "\n",
    "The Last.fm dataset contains multiple tags for each song in the Million Song Dataset. Some of the tags are genre-related, such as \"pop\", \"rock\", \"classic\", etc.  To obtain our dataset, we first extracted songs with Last.fm tags that included the words \"country\", or \"hip\" and \"hop\". These songs were then cross-referenced with the musiXmatch dataset, and only songs with musixMatch lyrics were placed into our dataset. Finally, inappropriate words and songs with naughty titles were removed, leaving us with 4976 words in the vocabulary and 1726 songs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Word Stemming\n",
    "The columns other than Title, Artist, and Genre in the `lyrics` table are all words that appear in some of the songs in our dataset.  Some of those names have been *stemmed*, or abbreviated heuristically, in an attempt to make different [inflected](https://en.wikipedia.org/wiki/Inflection) forms of the same base word into the same string.  For example, the column \"manag\" is the sum of proportions of the words \"manage\", \"manager\", \"managed\", and \"managerial\" (and perhaps others) in each song.  \n",
    "\n",
    "Stemming makes it a little tricky to search for the words you want to use, so we have provided another table that will let you see examples of unstemmed versions of each stemmed word.  Run the code below to load it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Stemming is normally a tricky operation. However,  we will do a simple operation for that. For a given word, first remove \"s\" at the end (if any).) \n",
    "Next, if the remaning part of the word ends with \"er\", remove it.\n",
    "Next, if the remaning part of the word is longer than 5 letters, take the only first five letters.\n",
    "Complete the function given below which returns stemmed version of a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer should be here\n",
    "def stemmer(word):\n",
    "    if word[len(word)-1:]==\"s\":\n",
    "        word = word[:len(word)-1]\n",
    "        if word[len(word)-2:]==\"er\":\n",
    "            word = word[:len(word)-2]\n",
    "            if len(word)>5:\n",
    "                word = word[0:5]     \n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** Run your stemmer function for the following words: yes, manager, hers, function and print their output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes: ye\n",
      "manager: manager\n",
      "hers: h\n",
      "function: function\n"
     ]
    }
   ],
   "source": [
    "# your answer should be here\n",
    "wordsStemmer = [\"yes\",\"manager\",\"hers\",\"function\"]\n",
    "for i in wordsStemmer:\n",
    "    print(i + \": \" + stemmer(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3** Count the number of characters, the number of words, and the number of unique words in the \"text.txt\". To count the number of characters, you should count every character except  spaces, dots and commas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of characters:\t 9973 \n",
      "The number of words:\t 1771 \n",
      "The number of unique words:\t 778\n"
     ]
    }
   ],
   "source": [
    "# your answer should be here\n",
    "character_length = 0\n",
    "word_count = 0\n",
    "unique_word_count = 0\n",
    "unique_words = []\n",
    "file = open(\"text.txt\",\"r\")    \n",
    "\n",
    "for lineString in file:    \n",
    "    words = lineString.split(' ')\n",
    "    word_count =  word_count + len(words)\n",
    "    for x in words:\n",
    "        if x not in unique_words:\n",
    "            unique_word_count = unique_word_count + 1\n",
    "            unique_words.append(x)\n",
    "        for y in x:\n",
    "            if y!=\",\" and y!=\".\" and y!= \" \":\n",
    "                character_length = character_length + 1 \n",
    "    \n",
    "file.close()    \n",
    "print(\"The number of characters:\\t\", character_length, \n",
    "      \"\\nThe number of words:\\t\",word_count,\n",
    "        \"\\nThe number of unique words:\\t\",unique_word_count,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4** Apply your stemmer function to every word in the document text.txt and print the number of characters of stemmed words, the number of stemmed words, and the number of unique stemmed words in the \"text.txt\". You should replace dots and commas with a space character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of characters of stemmed words:\t 2070 \n",
      "The number of stemmed words:\t 286 \n",
      "The number of unique stemmed words:\t 122\n"
     ]
    }
   ],
   "source": [
    "# your answer should be here\n",
    "character_length = 0\n",
    "word_count = 0\n",
    "unique_word_count = 0\n",
    "unique_words = []\n",
    "file = open(\"text.txt\",\"r\")\n",
    "def delCommaAndDot(word):\n",
    "    if word[len(word)-1:] == \".\" or word[len(word)-1:] == \",\":\n",
    "        word = word[0:len(word)-1]\n",
    "    return word\n",
    "\n",
    "for lineString in file:\n",
    "    words = lineString.split(' ')\n",
    "    words = [delCommaAndDot(element) for element in words] \n",
    "    for x in words:\n",
    "        if x!=stemmer(x):\n",
    "            character_length = character_length + len(x)\n",
    "            word_count = word_count +1 \n",
    "            if x not in unique_words:\n",
    "                unique_words.append(x)\n",
    "                unique_word_count = unique_word_count + 1\n",
    "    \n",
    "file.close()\n",
    "print(\"The number of characters of stemmed words:\\t\", character_length, \n",
    "      \"\\nThe number of stemmed words:\\t\",word_count,\n",
    "     \"\\nThe number of unique stemmed words:\\t\",unique_word_count,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Splitting the dataset\n",
    "We're going to use our `lyrics` dataset for three purposes.  First, we want to *train* various song genre classifiers.  Second, we want to *validate* which classifier is most effective. Finally, we want to *test* the performance of our final classifier. Hence, we need three different datasets: *training*, *validation*, and *test*.\n",
    "\n",
    "The purpose of a classifier is to generalize to unseen data that is similar to the training data. Therefore, we must ensure that there are no songs that appear in two different sets. We do so by splitting the dataset randomly. The dataset has already been permuted randomly, so it's easy to split.  We just take the top for training, the next part for validation, and the last for test. \n",
    "\n",
    "Run the code below (without changing it) to separate the three datasets into tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  1075 ; Validation:  322 ; Test:  324\n"
     ]
    }
   ],
   "source": [
    "# Here we have defined the proportion of our data\n",
    "# that we want to designate for training as 10/16ths\n",
    "# of our total dataset.  3/16ths of the data is\n",
    "# reserved for validation.  The remaining 3/16ths\n",
    "# will be used for testing.\n",
    "\n",
    "training_proportion = 10/16\n",
    "validation_proportion = 3/16\n",
    "num_songs = lyrics.shape[0]\n",
    "\n",
    "num_train = int(num_songs * training_proportion)\n",
    "num_valid = int(num_songs * validation_proportion)\n",
    "num_test = num_songs - num_train - num_valid\n",
    "\n",
    "train_lyrics = lyrics.take(range(num_train))\n",
    "valid_lyrics = lyrics.take(range(num_train, num_train + num_valid))\n",
    "test_lyrics = lyrics.take(range(num_train + num_valid, num_songs))\n",
    "\n",
    "print(\"Training: \",   train_lyrics.shape[0], \";\",\n",
    "      \"Validation: \", valid_lyrics.shape[0], \";\",\n",
    "      \"Test: \",       test_lyrics.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2.1.** Draw a bar chart with three bars that shows the number of Hip-hop songs in each of the three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write your answer here\n",
    "trainNumberOfHipHop = train_lyrics[train_lyrics[\"Genre\"]==\"Hip-hop\"].shape[0]\n",
    "\n",
    "validNumberOfHipHop = valid_lyrics[valid_lyrics[\"Genre\"]==\"Hip-hop\"].shape[0]\n",
    "\n",
    "testNumberOfHipHop = test_lyrics[test_lyrics[\"Genre\"]==\"Hip-hop\"].shape[0]\n",
    "\n",
    "barChartNumberOfHipHop = pd.DataFrame({\"Train\": [trainNumberOfHipHop],\n",
    "                                       \"Valid\": [validNumberOfHipHop],\n",
    "                                       \"Test\":  [testNumberOfHipHop]})\n",
    "barChartNumberOfHipHop.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. K-Nearest Neighbors - a Guided Example\n",
    "\n",
    "K-Nearest Neighbors (k-NN) is a classification algorithm.  Given some *features* of an unseen example, it decides whether that example belongs to one or the other of two categories based on its similarity to previously seen examples.  \n",
    "\n",
    "A feature we have about each song is *the proportion of times a particular word appears in the lyrics*, and the categories are two music genres: hip-hop and country.  The algorithm requires many previously seen examples for which both the features and categories are known: that's the `train_lyrics` table.\n",
    "\n",
    "We're going to visualize the algorithm, instead of just describing it. To get started, let's pick colors for the genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell to define genre_color.\n",
    "\n",
    "def genre_color(genre):\n",
    "    \"\"\"Assign a color to each genre.\"\"\"\n",
    "    if genre == 'Country':\n",
    "        return 'gold'\n",
    "    elif genre == 'Hip-hop':\n",
    "        return 'blue'\n",
    "    else:\n",
    "        return 'green'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Classifying a  song\n",
    "\n",
    "In k-NN, we classify a song by finding the `k` songs in the *training set* that are most similar according to the features we choose. We call those songs with similar features the \"neighbors\".  The k-NN algorithm assigns the song to the most common category among its `k` neighbors.\n",
    "\n",
    "Let's limit ourselves to just 2 features for now, so we can plot each song.  The features we will use are the proportions of the words \"like\" and \"love\" in the lyrics.  Taking the song \"In Your Eyes\" (in the test set), 0.0119 of its words are \"like\" and 0.0595 are \"love\". This song appears in the test set, so let's imagine that we don't yet know its genre.\n",
    "\n",
    "First, we need to make our notion of similarity more precise.  We will say that the *dissimilarity*, or *distance* between two songs is the straight-line distance between them when we plot their features in a scatter diagram. This distance is called the cosine distance.  \n",
    "\n",
    "For example, in the song *Insane in the Brain* (in the training set), 0.0203 of all the words in the song are \"like\" and 0 are \"love\".  Its distance from *In Your Eyes* on this 2-word feature set is $1-\\frac{((0.0119*0.0203) + (0.0595*0))}{ \\sqrt{0.0119^2 +0.0595^2} * \\sqrt{0.0203^2 + 0^2} } \\approx 0.20$.  (If we included more or different features, the distance could be different.)\n",
    "\n",
    "\n",
    "The function below creates a plot to display a test song and some training songs in a two-dimensional space defined by two features. As you can see in the result, *In Your Eyes* is more similar to *Sangria Wine* than to *Insane in the Brain*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just run this cell.\n",
    "def plot_with_two_features(test_song, training_songs, x_feature, y_feature):\n",
    "    \"\"\"Plot a test song and training songs using two features.\"\"\"\n",
    "    test_row = row_for_title(test_song)\n",
    "    distances = pd.DataFrame({\n",
    "            x_feature: [test_row[x_feature]],\n",
    "            y_feature: [test_row[y_feature]],\n",
    "            'Color':   [genre_color('Unknown')],\n",
    "            'Title':   [test_song]\n",
    "        }\n",
    "    )\n",
    "    i=1\n",
    "    for song in training_songs:\n",
    "        row = row_for_title(song)\n",
    "        color = genre_color(row['Genre'])\n",
    "        distances.loc[i] = [row[x_feature], row[y_feature], color, song]\n",
    "        i = i+1\n",
    "    \n",
    "    distances.plot(x_feature, y_feature,kind=\"scatter\",c=\"Color\",s=200)\n",
    "    \n",
    "    \n",
    "training = [\"Sangria Wine\", \"Insane In The Brain\"]\n",
    "plot_with_two_features(\"In Your Eyes\", training, \"like\", \"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1.1.** Compute the Cosine distance between the two country songs, *Dixie Fried* and *Lonelier Than This* on the `['you', 'life','world',dream']` feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2928932188134524"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dixie_fried = row_for_title(\"Dixie Fried\")\n",
    "lonelier_than_this = row_for_title(\"Lonelier Than This\")\n",
    "def cosineDistance(song1,song2,features):\n",
    "    row1 = row_for_title(song1)\n",
    "    row2 = row_for_title(song2)\n",
    "    top = 0\n",
    "    for i in features:\n",
    "        top = row1[i]*row2[i] + top\n",
    "    bottom1 = 0\n",
    "    for i in features:\n",
    "        bottom1 = row1[i] * row1[i] + bottom1\n",
    "    bottom2 = 0    \n",
    "    for i in features:\n",
    "        bottom2 = row2[i] * row2[i] + bottom2\n",
    "    if bottom1!=0 and bottom2!=0:\n",
    "        return 1 - (top/((bottom1*bottom2)**0.5))\n",
    "    return 0\n",
    "\n",
    "country_distance = cosineDistance(\"Dixie Fried\",\"Lonelier Than This\",['you', 'life','world','dream'])\n",
    "country_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1.2.** Complete the function `distance_four_features` that computes the Cosine distance between any two songs, using four features. The last two lines call the `distance_four_features` function  to show that *Lookin' for Love* is closer to *In Your Eyes* than *Insane In The Brain*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookin' for Love distance:\t 0.15484574932822492\n",
      "Insane In The Brain distance:\t 0.057091941076588215\n"
     ]
    }
   ],
   "source": [
    "def distance_four_features(title0, title1, x1_feature, x2_feature,x3_feature,x4_feature):\n",
    "    row1 = row_for_title(title0)\n",
    "    row2 = row_for_title(title1)\n",
    "    \n",
    "    features = [x1_feature,x2_feature,x3_feature,x4_feature]\n",
    "    \n",
    "    top = 0\n",
    "    for i in features:\n",
    "        top = row1[i]*row2[i] + top\n",
    "    bottom1 = 0\n",
    "    for i in features:\n",
    "        bottom1 = row1[i] * row1[i] + bottom1\n",
    "    bottom1 = bottom1 ** 0.5    \n",
    "    bottom2 = 0    \n",
    "    for i in features:\n",
    "        bottom2 = row2[i] * row2[i] + bottom2\n",
    "    bottom2 = bottom2 ** 0.5    \n",
    "    if bottom1!=0 and bottom2!=0:\n",
    "        return 1 - (top/(bottom1*bottom2))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for song in [\"Lookin' for Love\", \"Insane In The Brain\"]:\n",
    "    song_distance = distance_four_features(song, \"In Your Eyes\", \"you\", \"life\",\"world\",\"dream\")\n",
    "    print(song, 'distance:\\t', song_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nearest neighbor to a song is the example in the training set that has the smallest distance from that song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1.3.** Define the higher-order function `distance_from` that takes a single song title and two features. It returns a function `for_song` that takes a second song title and computes the distance between the first and second songs.\n",
    "\n",
    "*Hint: Call `distance_four_features` in your solution rather than re-implementing its computation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15484574932822492"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distance_from(title0, x1_feature, x2_feature,x3_feature,x4_feature):\n",
    "    def for_song(title1):\n",
    "        return distance_four_features(title0,title1,x1_feature,x2_feature,x3_feature,x4_feature)\n",
    "    return for_song\n",
    "\n",
    "distance_from_in_your_eyes = distance_from(\"In Your Eyes\", \"you\", \"life\",\"world\",\"dream\")\n",
    "distance_from_in_your_eyes(\"Lookin' for Love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1.4.**  What are the names and genres of the 7 closest songs to \"You're Just a Country Boy\" in  `train_lyrics`, by Cosine distance for the 4 features \"you\", \"life\",\"world\", and \"dream\"?  To answer this question, make a table named `closest_songs` containing those 7 songs with columns \"Title\", \"Artist\", \"Genre\", \"you\", \"life\",\"world\", and \"dream\" from the `lyrics` table, as well as a column called `cosine_distance` that contains the distance from \"You're Just a Country Boy\" **sorted in ascending order**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Genre</th>\n",
       "      <th>you</th>\n",
       "      <th>life</th>\n",
       "      <th>world</th>\n",
       "      <th>dream</th>\n",
       "      <th>cosine_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>Sharp Dressed Man (Album Version)</td>\n",
       "      <td>Brad Paisley</td>\n",
       "      <td>Country</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Easy Money</td>\n",
       "      <td>Brad Paisley</td>\n",
       "      <td>Country</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Dip It Low</td>\n",
       "      <td>Christina Milian</td>\n",
       "      <td>Hip-hop</td>\n",
       "      <td>0.057026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>The Leather Winged Bat</td>\n",
       "      <td>The Duhks</td>\n",
       "      <td>Country</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Sofern Du mir nah bist</td>\n",
       "      <td>SÃ¶hne Mannheims</td>\n",
       "      <td>Hip-hop</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>Sawing on the Strings</td>\n",
       "      <td>Alison Krauss</td>\n",
       "      <td>Country</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>Musique De La Jungle</td>\n",
       "      <td>Akhenaton</td>\n",
       "      <td>Hip-hop</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title            Artist    Genre       you  \\\n",
       "537  Sharp Dressed Man (Album Version)      Brad Paisley  Country  0.007937   \n",
       "619                         Easy Money      Brad Paisley  Country  0.024096   \n",
       "620                         Dip It Low  Christina Milian  Hip-hop  0.057026   \n",
       "621             The Leather Winged Bat         The Duhks  Country  0.011583   \n",
       "622             Sofern Du mir nah bist   SÃ¶hne Mannheims  Hip-hop  0.000000   \n",
       "624              Sawing on the Strings     Alison Krauss  Country  0.000000   \n",
       "625               Musique De La Jungle         Akhenaton  Hip-hop  0.000000   \n",
       "\n",
       "     life  world  dream  cosine_distance  \n",
       "537   0.0    0.0    0.0              0.0  \n",
       "619   0.0    0.0    0.0              0.0  \n",
       "620   0.0    0.0    0.0              0.0  \n",
       "621   0.0    0.0    0.0              0.0  \n",
       "622   0.0    0.0    0.0              0.0  \n",
       "624   0.0    0.0    0.0              0.0  \n",
       "625   0.0    0.0    0.0              0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "like_love = train_lyrics[[\"Title\", \"Artist\", \"Genre\", \"you\", \"life\",\"world\",  \"dream\" ]]\n",
    "like_love = like_love.copy(deep=True)\n",
    "distances = []\n",
    "for x in range(len(train_lyrics)):\n",
    "    distances.append(distance_four_features(like_love.iloc[x][\"Title\"], \"You're Just a Country Boy\", \"you\", \"life\",\"world\",\"dream\"))\n",
    "like_love[\"cosine_distance\"] = distances\n",
    "like_love = like_love.sort_values(by=\"cosine_distance\",key=lambda x: abs(x))\n",
    "closest_songs = like_love.head(7)\n",
    "closest_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1.5.** Write a function `most_common` that takes a `column_label` and a `table`. It returns the most common value in that column of that table. In case of a tie, it can return any of the most common values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n"
     ]
    }
   ],
   "source": [
    "def most_common(column_label, table):\n",
    "    indeks = pd.unique(table[column_label])\n",
    "    arr = []\n",
    "    for x in range(len(indeks)):\n",
    "        arr.append(0)\n",
    "    for x in range(len(table)):\n",
    "        for i in range(len(indeks)):\n",
    "            if indeks[i]==table[column_label].iloc[x]:\n",
    "                arr[i] = arr[i] + 1\n",
    "    maxV = 0\n",
    "    maxI = -1\n",
    "    for x in range(len(arr)):\n",
    "        if arr[x]>maxV:\n",
    "            maxV= arr[x]\n",
    "            maxI = x\n",
    "    return indeks[maxI]        \n",
    "print(most_common('Genre', closest_songs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations are in order -- you've classified your first song!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to extend our classifier to consider more than four features at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.** Write a function to compute the Cosine distance between two *arrays* of features of *arbitrary* (but equal) length.  Use it to compute the distance between the first song in the training set and the first song in the test set, *using all of the features*.  (Remember that the title, artist, and genre of the songs are not features.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5035344605105948"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distance(features1, features2):\n",
    "    top = 0\n",
    "    for i in range(len(features1)):\n",
    "        top = features1[i] * features2[i] + top\n",
    "    bottom1 = 0\n",
    "    for i in range(len(features1)):\n",
    "        bottom1 = features1[i] * features1[i] + bottom1\n",
    "    bottom1 = bottom1 ** 0.5\n",
    "    bottom2 = 0\n",
    "    for i in range(len(features2)):\n",
    "        bottom2 = features2[i] * features2[i] + bottom2\n",
    "    bottom2 = bottom2 ** 0.5\n",
    "    if bottom1==0 or bottom2==0:\n",
    "        return 0\n",
    "    return 1 - (top/(bottom1*bottom2))\n",
    "trainFirst = train_lyrics.loc[0]\n",
    "trainFirst = trainFirst.drop([\"Title\",\"Artist\",\"Genre\"])\n",
    "testFirst = test_lyrics.iloc[0]\n",
    "testFirst = testFirst.drop([\"Title\",\"Artist\",\"Genre\"])\n",
    "distance_first_to_first = distance(np.array(trainFirst), np.array(testFirst))\n",
    "distance_first_to_first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Creating your own feature set\n",
    "\n",
    "Unfortunately, using all of the features has some downsides.  We'll explore that more later, but one clear downside is *computational* -- computing Cosine distances just takes a long time when we have lots of features.  So we're going to select just 25 for now.  We'd like to choose features that are very *discriminative*, that is, which lead us to correctly classify as much of the test set as possible.  This process of choosing features that will make a classifier work well is sometimes called *feature selection*, or more broadly *feature engineering*.\n",
    "\n",
    "**3.1.1.** Look through the list of features (the labels of the `lyrics` table after the first three).  Choose 25 that you think will let you distinguish pretty well between country and hip-hop songs.  You might want to come back to this question later to improve your list, once you've seen how to evaluate your classifier.  The first time you do this question, spend some time looking through the features, but not more than 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set my_25_features to a list of 25 features (strings that are column labels)\n",
    "\n",
    "my_25_features = ['angel','true', 'fool', 'mine', 'will', 'late',\n",
    "       'for', 'no', 'lie', 'him', 'love', 'free', 'know', 'men', 'but', 'with',\n",
    "       'what', 'girl', 'when', 'like', 'now',\"life\",\"never\",\"heart\",\"bed\"]\n",
    "train_25 = train_lyrics[my_25_features]\n",
    "test_25 = test_lyrics[my_25_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.2** In a few sentences, describe how you selected your features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to pick features with more emotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Any rationale is ok as long as it is not random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's classify the first song from our test set using these features.  You can examine the song by running the cells below. Do you think it will be classified correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title     Put 'Em On The Glass\n",
       "Artist           Sir Mix-A-Lot\n",
       "Genre                  Hip-hop\n",
       "Name: 1397, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lyrics.iloc[0][['Title', 'Artist', 'Genre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "angel    0.000000\n",
       "true     0.000000\n",
       "fool     0.000000\n",
       "mine     0.001912\n",
       "will     0.001912\n",
       "late     0.000000\n",
       "for      0.003824\n",
       "no       0.001912\n",
       "lie      0.000000\n",
       "him      0.000000\n",
       "love     0.000000\n",
       "free     0.000000\n",
       "know     0.000000\n",
       "men      0.000000\n",
       "but      0.005736\n",
       "with     0.009560\n",
       "what     0.003824\n",
       "girl     0.007648\n",
       "when     0.001912\n",
       "like     0.003824\n",
       "now      0.005736\n",
       "life     0.000000\n",
       "never    0.003824\n",
       "heart    0.000000\n",
       "bed      0.000000\n",
       "Name: 1397, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_25.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.3**  As before, we want to look for the songs in the training set that are most alike our test song.  We will calculate the Cosine distances from the test song (using the 25 selected features) to all songs in the training set. Define `distances` function to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(test_row, train_rows):\n",
    "    distanceS1 = []\n",
    "    for x in range(len(train_rows)):\n",
    "        distanceS1.append(distance(test_row,train_rows.iloc[x]))\n",
    "    return distanceS1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.4.** Use the `distances` function provided above to compute the distance of the first song in the test set to all the songs in the training set.  Make a new table called `genre_and_distances` with one row for each song in the training set and two columns:\n",
    "* The `\"Genre\"` of the training song\n",
    "* The `\"Distance\"` from the first song in the test set \n",
    "\n",
    "Ensure that `genre_and_distances` is **sorted by increasing distance to the first test song**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>Hip-hop</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Hip-hop</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Hip-hop</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Hip-hop</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Hip-hop</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>Hip-hop</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Country</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Hip-hop</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Hip-hop</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>Country</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1075 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Genre  Distance\n",
       "818  Hip-hop       0.0\n",
       "585  Hip-hop       0.0\n",
       "592  Hip-hop       0.0\n",
       "251  Hip-hop       0.0\n",
       "116  Hip-hop       0.0\n",
       "..       ...       ...\n",
       "710  Hip-hop       1.0\n",
       "376  Country       1.0\n",
       "20   Hip-hop       1.0\n",
       "982  Hip-hop       1.0\n",
       "612  Country       1.0\n",
       "\n",
       "[1075 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def genres(rows):\n",
    "    genreS = []\n",
    "    for x in range(len(rows)):\n",
    "        genreS.append(rows.iloc[x][\"Genre\"])\n",
    "    return genreS\n",
    "\n",
    "\n",
    "        \n",
    "distance1 = distances(test_25.iloc[0],train_25)\n",
    "genres(train_lyrics)\n",
    "genre_and_distances = pd.DataFrame({\"Genre\":genres(train_lyrics),\"Distance\":distance1}).sort_values(by=\"Distance\")\n",
    "genre_and_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.5.**  Now compute the 7-nearest neighbors classification of the second song in the test set.  That is, decide on its genre by finding the most common genre among its 7 nearest neighbors, according to the distances you've calculated.  Then check whether your classifier chose the right genre.  (Depending on the features you chose, your classifier might not get this song right, and that's okay.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The assigned genre Hip-hop was correct... False\n"
     ]
    }
   ],
   "source": [
    "# Set my_assigned_genre to the most common genre among these.\n",
    "genre_and_distances[\"Distance\"] = distances(test_25.iloc[1],train_25)\n",
    "my_assigned_genre = most_common(\"Genre\",genre_and_distances.head(7))\n",
    "my_assigned_genre\n",
    "# Set my_assigned_genre_was_correct to True if my_assigned_genre\n",
    "# matches the actual genre of the first song in the test set.\n",
    "my_assigned_genre_was_correct = my_assigned_genre==test_lyrics[\"Genre\"].iloc[1]\n",
    "\n",
    "print(\"The assigned genre\", my_assigned_genre, \"was correct...\", my_assigned_genre_was_correct )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. A classifier function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to write a single function that encapsulates this whole process of classification.\n",
    "\n",
    "**3.2.1.** Write a function called `classify`.  It should take the following arguments:\n",
    "* An array of features for a song to classify (e.g., `test_25.row(0)`),\n",
    "* A table with a column for each feature (for example, `train_25`)\n",
    "* An array of classes that has as many items as the previous table has rows, and in the same order, and\n",
    "* `k`, the number of neighbors to use in classification.\n",
    "\n",
    "It should return the class your classifier picks for the given row of features (e.g., `'Country'` or `'Hip-hop'`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(test_row, train_rows, train_classes, k):\n",
    "    distance1F = distances(test_row,train_rows)\n",
    "    genre_and_distancesF = pd.DataFrame({\"Genre\":genres(train_classes),\"Distance\":distance1F}).sort_values(by=\"Distance\",key=lambda x: abs(x))\n",
    "    return most_common(\"Genre\",genre_and_distancesF.head(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.2.** Assign `guitar_genre` to the genre predicted by your classifier for the song  \"Guitar Town\" in the test set, using 7 neigbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hip-hop'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index1 = test_lyrics[test_lyrics[\"Title\"]==\"Guitar Town\"][my_25_features].reset_index()[\"index\"][0]\n",
    "\n",
    "guitar_genre = classify(test_25.loc[index1], train_25,train_lyrics,7)\n",
    "guitar_genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.3** To simplify things further, use the higher-order function `classify_using` that takes `train_rows`, `train_classes`, and `k` to define a function `simple_classify`. The `simple_classify` function should take just one argument, a test row, and return the predicted genre of a song using `train_25` and seven neighbors (`k` of 7).  This way, when we classify a song, we just have to pass in the song's features, not the whole training set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hip-hop'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify_using(train_rows, train_classes, k):\n",
    "    def for_row(test_row):\n",
    "        return classify(test_row, train_rows, train_classes, k)\n",
    "    return for_row\n",
    "\n",
    "def simple_classify(test_row):\n",
    "    return classify_using(train_25,train_lyrics,7)(test_row)\n",
    "simple_classify(test_25.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Evaluating your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that it's easy to use the classifier, let's see how accurate it is on the whole test set.\n",
    "\n",
    "**3.3.1.** Classify every song in the test set (provided), then compute the proportion of correct classifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4567901234567901"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for x in range(len(test_25)): \n",
    "    if simple_classify(test_25.iloc[x])==test_lyrics.iloc[x][\"Genre\"]:\n",
    "        results.append(1)\n",
    "    else :\n",
    "        results.append(0)\n",
    "proportion_correct = sum(results)/len(results)\n",
    "proportion_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you've gone through one cycle of classifier design.  Let's summarize the steps:\n",
    "1. From available data, select test and training sets.\n",
    "2. Choose an algorithm you're going to use for classification.\n",
    "3. Identify some features.\n",
    "4. Define a classifier function using your features and the training set.\n",
    "5. Evaluate its performance (the proportion of correct classifications) on the test set.\n",
    "\n",
    "In practice, if the performance is good enough for your application, you might be done. In this case, we might be able to do better by focusing on step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature design\n",
    "\n",
    "One way to interpret the accuracy of a classifier is to compare it to another classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.0.1.** Below we've provided 10 features selected by the staff.  Build a 11-nearest-neighbor classifier using these features and compute its accuracy on the test set. (You can write any code you want, as long as `proportion_correct_staff` is computed correctly; the other names are only suggestions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4567901234567901"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_staff = [\"come\", \"do\", \"love\", \"like\", \"make\", \"never\", \"now\", \"wanna\", \"with\", \"yo\"]\n",
    "train_staff = ...\n",
    "test_staff = ...\n",
    "classify_staff = ...\n",
    "guesses_staff = ...\n",
    "res = []\n",
    "for x in range((len(test_lyrics))): \n",
    "    if test_lyrics.iloc[x][\"Genre\"] == classify(test_lyrics.iloc[x][features_staff],\n",
    "                                               train_lyrics[features_staff],\n",
    "                                               train_lyrics,11):\n",
    "        res.append(1)\n",
    "    else:\n",
    "        res.append(0)\n",
    "proportion_correct_staff = sum(res)/len(res)\n",
    "\n",
    "\n",
    "proportion_correct_staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.0.2.** Are the features you chose better or worse than the staff features at classifying the test set? Why do you think this is so?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that the features i choose are worse than staff features because in test data, the staff features have a higher proportion of correct genres than the features i choose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.0.3.** Is there anything random about a classifier's accuracy measured in this way?  Is it possible that the difference in classifier performance is due to chance?  If so, describe (in 2-3 sentences) how you would investigate that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think it is not random. I would investigate it with the kfold method and compare performances in\n",
    "each fold. If there are huge differences in performances then maybe there can be something random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we use only use a subset of the staff features? Is there a single feature that's better than the rest? Can removing features improve our classifier? Does removing features always hurt? If so, does removing different features degrade accuracy by different amounts?\n",
    "\n",
    "As soon as you begin comparing the performance of many different classifiers, searching for the best one, it is important to conduct that search on the *validation set* rather than the *test set*. Conventionally, the test set is used for evaluation of methods. The validation set is used to select exactly how a method is applied, such as choosing a set of features or a value for `k`.  The validation set is called `valid_lyrics`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1.1.** Define a higher-order function `accuracy_on` that takes an evaluation set, either `valid_lyrics` or `test_lyrics`. It returns a function that takes a feature list and a value for `k`, and returns the accuracy (proprotion correct) of a `k`-NN classifier on the evaluation set using those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9932885906040269"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy_on(evaluation_set):\n",
    "    def accuracy(features, k):\n",
    "        train =  train_lyrics[features]                   # select the features from train_lyrics \n",
    "        validation =  evaluation_set[features]                 # select the features from evaluation_set\n",
    "        classifier = features\n",
    "        guesses = ...\n",
    "        resul = []\n",
    "        for x in range(len(evaluation_set)): \n",
    "            if evaluation_set.iloc[x][\"Genre\"] == classify(validation.iloc[x],\n",
    "                                               train,\n",
    "                                               train_lyrics,k):\n",
    "                resul.append(1)\n",
    "        else:\n",
    "            resul.append(0)\n",
    "        return  sum(resul)/len(resul)\n",
    "    return accuracy\n",
    "\n",
    "valid_accuracy = accuracy_on(valid_lyrics) \n",
    "valid_accuracy(features_staff, 5)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1.2.** Create a two-column table `single_feature_accuracies` that shows the accuracy on the validation set using 7 neighbors and only a single feature. Include a row for every feature in `features_staff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.993333</td>\n",
       "      <td>come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.993333</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.993333</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.993333</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.993333</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.993333</td>\n",
       "      <td>never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.993333</td>\n",
       "      <td>now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.993333</td>\n",
       "      <td>wanna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.993333</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.993333</td>\n",
       "      <td>yo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy Features\n",
       "0  0.993333     come\n",
       "1  0.993333       do\n",
       "2  0.993333     love\n",
       "3  0.993333     like\n",
       "4  0.993333     make\n",
       "5  0.993333    never\n",
       "6  0.993333      now\n",
       "7  0.993333    wanna\n",
       "8  0.993333     with\n",
       "9  0.993333       yo"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_feature_accuracies = []\n",
    "for f in features_staff:\n",
    "    single_feature_accuracies.append(accuracy_on(valid_lyrics)([f], 7))\n",
    "single_feature_accuracies = pd.DataFrame({\"Accuracy\": single_feature_accuracies,\n",
    "                                          \"Features\": features_staff}) \n",
    "single_feature_accuracies.sort_values(by=\"Accuracy\", ascending=False) # sort by the their accuracy in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An *ablation* study involves attempting to determine which features matter most for classification accuracy by removing (\"ablating\") each of them individually.\n",
    "\n",
    "**4.1.3.** Create a two-column table `ablation_accuracies` that shows the accuracy on the validation set of a 7-NN classifier that has all `features_staff` except one. Include a row for every feature in `features_staff` that you leave out. (*Hint*: Lists have a `.remove` method that takes the element to be removed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Removed Feature</th>\n",
       "      <th>All-Except-One Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love</td>\n",
       "      <td>0.993939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do</td>\n",
       "      <td>0.993750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>0.993506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>now</td>\n",
       "      <td>0.993464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>with</td>\n",
       "      <td>0.993464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>never</td>\n",
       "      <td>0.993421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wanna</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yo</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>make</td>\n",
       "      <td>0.993289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>come</td>\n",
       "      <td>0.993151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Removed Feature  All-Except-One Accuracy\n",
       "2            love                 0.993939\n",
       "1              do                 0.993750\n",
       "3            like                 0.993506\n",
       "6             now                 0.993464\n",
       "8            with                 0.993464\n",
       "5           never                 0.993421\n",
       "7           wanna                 0.993333\n",
       "9              yo                 0.993333\n",
       "4            make                 0.993289\n",
       "0            come                 0.993151"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablation_accuracies = pd.DataFrame({\"Removed Feature\":[],\n",
    "                                   \"All-Except-One Accuracy\":[]})\n",
    "                                        # create a dataframe with columns 'Feature', and 'All-Except-One Accuracy']\n",
    "for f in features_staff:\n",
    "    features1 = list(features_staff) # Make a copy of the staff features\n",
    "    features1.remove(f)              # Remove one feature from the copy\n",
    "    ablation_accuracies = ablation_accuracies.append(pd.DataFrame({\"Removed Feature\":[f],\n",
    "                               \"All-Except-One Accuracy\":[accuracy_on(valid_lyrics)(features1, 7)]}),\n",
    "                                ignore_index = True)\n",
    "ablation_accuracies.sort_values(by=\"All-Except-One Accuracy\",ascending=False) # sort by the their accuracy in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1.5.** Draw a scatter diagram with one dot for every **odd** value of `k` from 1 to 15 (inclusive) that plots the accuracy on the validation set on the horizontal axis and accuracy on the test set on the vertical axis. Use `features_staff` as the features for all points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validationH = []\n",
    "testV = [] \n",
    "for x in [1,3,5,7,9,11,13,15]:\n",
    "    validationH.append(accuracy_on(valid_lyrics)(features_staff, x))\n",
    "    testV.append(accuracy_on(test_lyrics)(features_staff, x))\n",
    "a = pd.DataFrame({\"Validation\":validationH,\"Test\":testV})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Validation', ylabel='Test'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.plot.scatter(y=\"Test\",x=\"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of the Project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
